# Story 2.3: Integrate Resolver into Screening Workflow

**Status:** Ready for Development

## Goal & Context

**User Story:** As a developer, I want the resolver agent to be automatically triggered after the initial dual-reviewer screening completes for a batch, so that disagreements are processed without manual intervention.

**Context:** This story builds upon the definition of core Pydantic schemas and resolver persistence (Story 2.1) and the implementation of the resolver agent/chain (Story 2.2). It focuses on integrating this resolver agent into the existing abstract screening workflow. **IMPORTANT**: This story represents the **BACKEND ARCHITECTURE** implementation while Story 2.4 handles the **UI INTEGRATION**.

**Current State**: The resolver chain works but bypasses the service layer architecture. This story implements the missing service-layer integration specified by the architect, ensuring proper data persistence and architectural compliance.

**Prerequisite Note & Current State of Screening:**
The abstract screening process, specifically the `screen_abstracts_chain_on_end_cb` callback and `screen_abstracts_batch` function in `src/sr_assistant/app/agents/screening_agents.py`, must be verified and restored to correctly produce `schemas.ScreeningResult` objects. A regression (likely from commit `b8d9509`) currently causes these functions to yield raw `schemas.ScreeningResponse` objects instead, leading to errors when `screen_abstracts.py` processes batch results. This fix is a primary task for Story 2.6, and the file **`src/sr_assistant/app/agents/screening_agents_old_working.py`** serves as a reference for the previously working implementation. Story 2.3 depends on `screen_abstracts.py` (or the service layer it will call) correctly identifying conflicts based on valid `ScreeningResult` objects for both conservative and comprehensive strategies. The current state where `ScreeningResponse` is incorrectly passed will prevent accurate conflict identification and thus block the main goal of this story.

## Detailed Requirements

(Copied from `docs/epics/epic2-recovery-resolver-implementation.md#Story-2.3`)

- In `src/sr_assistant/app/pages/screen_abstracts.py`, after a batch of abstracts is screened by `screen_abstracts_chain`:
    - Identify disagreements: Iterate through results, find where conservative and comprehensive decisions differ (e.g., INCLUDE vs. EXCLUDE, as per `docs/prd-resolver.md` FR1). (Note: FR1 of `docs/prd-resolver.md` specifies that cases involving `UNCERTAIN` will not be considered disagreements for automated resolution in this iteration).
    - For each disagreement, prepare the full input context required by `resolver_prompt` (FR3 from `docs/prd-resolver.md`).
    - Invoke the `resolver_chain` (preferably in a batch call if supported and efficient, or iterate) for all identified disagreements in the current screening batch.
    - Process the output (an instance of `ResolverOutputSchema`) from the chain.
    - Create `ScreeningResolution` model instances.
    - Use `ScreeningResolutionRepository` to save the new resolution records.
    - Update the corresponding `SearchResult` records with the `final_decision` and `resolution_id`.
- Implement appropriate status indicators in the UI for the resolution process (e.g., "Resolving conflicts...").

## Acceptance Criteria (ACs)

(Copied from `docs/epics/epic2-recovery-resolver-implementation.md#Story-2.3`)

- AC1: Disagreements between conservative and comprehensive screeners are correctly identified in `screen_abstracts.py` after a batch screening (specifically INCLUDE vs. EXCLUDE or EXCLUDE vs. INCLUDE).
- AC2: For each identified disagreement, the `resolver_chain` is invoked with the correct input context.
- AC3: `ScreeningResolution` records are successfully created and stored in the database for each resolved conflict.
- AC4: `SearchResult` records are updated with the `final_decision` from the resolver and the `resolution_id`.
- AC5: The process handles cases where there are no disagreements (matching FR1 criteria) in a batch gracefully (i.e., resolver is not called).
- AC6: Unit tests for the disagreement identification and resolver invocation logic in `screen_abstracts.py` (mocking chain and repositories) pass.
- AC7: Integration tests verify that the resolver is correctly invoked for `INCLUDE` vs. `EXCLUDE` disagreements (and vice-versa).
- AC8: Integration tests verify that cases involving `UNCERTAIN` (e.g., `INCLUDE` vs. `UNCERTAIN`, `UNCERTAIN` vs. `UNCERTAIN`) are handled gracefully and *do not* trigger the resolver, adhering to FR1 of `docs/prd-resolver.md`.

## Technical Implementation Context

**Guidance:** Use the following details for implementation. Developer agent is expected to follow project standards in `docs/coding-standards.md` and understand the project structure in `docs/project-structure.md`. Only story-specific details are included below.

- **Relevant Files:**
    - Files to Modify:
        - `src/sr_assistant/app/pages/screen_abstracts.py` (Primary focus)
        - `src/sr_assistant/core/repositories.py` (Ensure `ScreeningResolutionRepository` and `SearchResultRepository` have necessary methods for creating resolutions and updating search results with final decisions, as established in Story 2.1)
        - `src/sr_assistant/core/services.py` (If helper methods are needed in `ScreeningService` to orchestrate parts of this, though primary logic is in `screen_abstracts.py` for this story)
    - Files to Create (Tests):
        - `tests/unit/app/pages/test_screen_abstracts_resolver_integration.py` (or similar, for unit tests of new logic in `screen_abstracts.py`)
        - `tests/integration/app/test_resolver_workflow.py` (or similar, for integration tests covering resolver invocation and DB updates)

- **Key Technologies:**
    - Streamlit (for `screen_abstracts.py` UI and logic)
    - Python, Pydantic, SQLModel, SQLAlchemy
    - LangChain (for `resolver_chain` invocation)

- **API Interactions / SDK Usage:**
    - Internal:
        - `screen_abstracts.py` will invoke the `resolver_chain` (from `screening_agents.py`, defined in Story 2.2).
        - `screen_abstracts.py` will use `ScreeningResolutionRepository.add()` (or a service method wrapping it) to store resolution results.
        - `screen_abstracts.py` will use `SearchResultRepository.update_final_decision()` (or similar, defined in Story 2.1) to update `SearchResult` records.
    - The `resolver_chain` itself interacts with an LLM API (e.g., OpenAI).

- **UI/UX Notes:**
    - A simple status indicator (e.g., `st.spinner("Resolving conflicts...")` or `st.info("Resolving conflicts...")`) should be displayed in `screen_abstracts.py` while the resolver is processing.
    - Detailed UI updates for displaying the final decision and resolver reasoning are primarily covered in Story 2.4. This story focuses on the backend integration and basic status.

- **Data Structures:**
    - `schemas.ResolverOutputSchema` (Output from `resolver_chain`)
    - `models.ScreeningResolution` (For creating records to store in DB)
    - `models.SearchResult` (For updating `final_decision` and `resolution_id`)
    - `models.ScreenAbstractResult` (For identifying disagreements between conservative and comprehensive strategies)

- **Environment Variables:**
    - Ensure `OPENAI_API_KEY` (or equivalent for the `RESOLVER_MODEL`) is available for the `resolver_chain` invocation.

- **Coding Standards Notes:**
    - Follow standards in `docs/coding-standards.md`.
    - Ensure efficient querying when identifying disagreements and fetching necessary data for the resolver.
    - The logic for identifying disagreements should be clear and correctly implement FR1 from `docs/prd-resolver.md` (INCLUDE vs. EXCLUDE only, no UNCERTAIN).

- **Project Structure Alignment:**
    - Modifications are primarily within `src/sr_assistant/app/pages/screen_abstracts.py`.
    - Ensure new test files are placed in the correct `tests/unit` or `tests/integration` subdirectories.

## Testing Requirements

**Guidance:** Verify implementation against the ACs using the following tests. Follow general testing approach in `docs/testing-strategy.md`.

- **Unit Tests (AC6):**
    - In `tests/unit/app/pages/test_screen_abstracts_resolver_integration.py`:
        - Test the disagreement identification logic within `screen_abstracts.py`. Mock `ScreenAbstractResult` data to simulate various scenarios (agreement, disagreement: INCLUDE vs. EXCLUDE, EXCLUDE vs. INCLUDE, cases involving UNCERTAIN).
        - Test the input preparation logic for `resolver_chain`.
        - Test the logic that calls `resolver_chain`, mocking the chain itself to return predefined `ResolverOutputSchema` instances.
        - Test the logic that calls `ScreeningResolutionRepository.add()` and `SearchResultRepository.update_final_decision()`, mocking these repository methods.
        - Verify that the resolver is not called when no disagreements (matching FR1 criteria) are found.
- **Integration Tests (AC7, AC8):**
    - In `tests/integration/app/test_resolver_workflow.py` (or similar, these tests may interact with the database and potentially a mocked/controlled LLM response for the resolver chain):
        - Test scenario: Create a `SystematicReview`, multiple `SearchResult` records, and corresponding `ScreenAbstractResult` records in the test database that represent clear INCLUDE vs. EXCLUDE disagreements.
            - Run the relevant part of `screen_abstracts.py` logic (or a service method if refactored there) that triggers disagreement identification and resolver invocation.
            - Mock the `resolver_chain` to return a specific, valid `ResolverOutputSchema` (e.g., deciding INCLUDE with a reason).
            - Verify that `ScreeningResolution` records are created in the database with correct data.
            - Verify that `SearchResult` records are updated with the correct `final_decision` and `resolution_id`.
        - Test scenario: Similar to above, but with `ScreenAbstractResult` records that involve `UNCERTAIN` decisions (e.g., INCLUDE vs. UNCERTAIN, UNCERTAIN vs. UNCERTAIN).
            - Verify that the resolver is *not* invoked.
            - Verify that no `ScreeningResolution` records are created for these cases.
            - Verify that `SearchResult.final_decision` remains null (or unchanged).
        - Consider a test that uses a controlled (mocked) LLM response for the `resolver_chain` if full LLM calls are too slow/expensive for frequent integration runs, ensuring the parsing and data flow from the chain output is correct.

## Tasks / Subtasks

- [ ] Task 2.3.1: **Implement Disagreement Identification Logic:**
    - In `screen_abstracts.py`, after batch screening, iterate through `ScreenAbstractResult` objects for each `SearchResult`.
    - Identify pairs where `conservative_decision` is INCLUDE and `comprehensive_decision` is EXCLUDE, or vice-versa.
    - Filter out disagreements involving `ScreeningDecisionType.UNCERTAIN` as per `docs/prd-resolver.md` FR1.
- [ ] Task 2.3.2: **Prepare Input for Resolver:**
    - For each identified disagreement, gather all necessary context for the `resolver_prompt` (from `SearchResult`, `SystematicReview`, and the differing `ScreenAbstractResult` details). This might involve fetching the full `SystematicReview` object if not already available.
- [ ] Task 2.3.3: **Invoke Resolver Chain:**
    - Call the `resolver_chain` (defined in Story 2.2, likely from `screening_agents.py`) with the prepared inputs.
    - Handle potential batch invocation if the chain and context preparation support it.
- [ ] Task 2.3.4: **Process Resolver Output & Persist Results:**
    - For each `ResolverOutputSchema` returned by the chain:
        - Create a `models.ScreeningResolution` instance.
        - Use `ScreeningResolutionRepository` (via `db_dependency` or service call) to save the resolution.
        - Update the corresponding `models.SearchResult` with the `final_decision` (from `ResolverOutputSchema.final_decision`) and the new `resolution_id`. Use `SearchResultRepository` or a service method.
- [ ] Task 2.3.5: **Implement UI Status Indicator:**
    - Add a simple status message (e.g., `st.spinner` or `st.info`) in `screen_abstracts.py` to indicate when conflict resolution is in progress.
- [ ] Task 2.3.6: **Develop Unit Tests (AC6):**
    - Create unit tests in `tests/unit/app/pages/test_screen_abstracts_resolver_integration.py` covering:
        - Disagreement identification logic (various scenarios).
        - Resolver input preparation.
        - Mocked resolver chain invocation and output processing.
        - Mocked repository calls for saving resolution and updating search results.
        - Scenario with no eligible disagreements.
- [ ] Task 2.3.7: **Develop Integration Tests (AC7, AC8):**
    - Create integration tests in `tests/integration/app/test_resolver_workflow.py` covering:
        - End-to-end flow for INCLUDE vs. EXCLUDE disagreements (with mocked resolver chain output), verifying DB changes.
        - Scenario where `UNCERTAIN` decisions do not trigger the resolver, verifying no DB changes related to resolution.
- [ ] Task 2.3.8: **Code Review & Refinement:**
    - Review the implemented logic for clarity, efficiency, and adherence to standards.
    - Ensure all ACs are met.

## Story Wrap Up (Agent Populates After Execution)

- **Agent Model Used:** `<Agent Model Name/Version>`
- **Completion Notes:** {Any notes about implementation choices, difficulties, or follow-up needed}
- **Change Log:**
    - Initial Draft by Technical Scrum Master Agent
