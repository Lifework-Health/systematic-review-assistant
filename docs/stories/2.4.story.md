# Story 2.4: Integrate Resolver Workflow and Update screen_abstracts.py UI & Logic

**Status:** SUPERSEDED by Story 2.4A

## Goal & Context

**User Story:** As a researcher, I want the abstract screening page (`screen_abstracts.py`) to seamlessly integrate the automated conflict resolution workflow, correctly interact with the refactored `ScreeningService`, and clearly display initial screening decisions, the resolution process status, final resolved decisions, and resolver reasoning, so that the screening process is efficient and transparent.

**Context:** This story addresses the critical architectural violation where `screen_abstracts.py` currently bypasses the service layer and directly calls resolver agents. The architect specified a proper UI → Service → Repository pattern that must be implemented. Currently, resolution data is only stored in Streamlit session state with no database persistence.

**Current Architectural Violations:**
- UI directly calls `invoke_resolver_chain()` from screening agents (bypassing service layer)
- No database persistence of resolver decisions
- No updates to `SearchResult.final_decision` field
- Resolution reasoning stored only in session state

## Detailed Requirements

### **1. Service Call Alignment (ScreeningService):**

**Modify `screen_abstracts.py` to use the updated `ScreeningService.add_screening_decision` method.** This involves:
- Calling it with `search_result_id`, `screening_strategy`, and a correctly populated `schemas.ScreeningResultCreate` object (which is derived from the `schemas.ScreeningResult` obtained from the `screen_abstracts_batch` LLM chain output).
- Ensure calls to methods like `ScreeningService.get_screening_decisions_for_search_result` or `get_screening_decisions_for_review` use the new signatures (no `session` parameter).
- Remove any direct session management from `screen_abstracts.py` related to these service calls.

### **2. Conflict Resolution Triggering:**

**After a batch of abstracts is screened** (i.e., after `screen_abstracts_batch` function completes and initial `ScreenAbstractResult` records are created via `ScreeningService.add_screening_decision`), `screen_abstracts.py` MUST call `ScreeningService.resolve_screening_conflicts_for_batch`.

Pass the current `models.SystematicReview` object and the list of `SearchResult` IDs from the just-screened batch to this service method.

### **3. UI Updates for Resolver Workflow:**

**Status Indication:** Display a status indicator in the UI while the `resolve_screening_conflicts_for_batch` method is processing (e.g., "Resolving conflicts...").

**Display Final Decisions:** The results display (e.g., Streamlit DataFrame or custom layout) in `screen_abstracts.py` MUST prioritize displaying `SearchResult.final_decision` if it is populated. If `final_decision` is null, the UI should clearly show the original individual decisions from the conservative and comprehensive screeners and indicate an 'unresolved' or 'pending resolution' status.

**Resolution Indicator:** If `SearchResult.resolution_id` is present (indicating a conflict was processed by the resolver), a clear visual cue (e.g., an icon, tag like "Resolved by AI") MUST be displayed next to the decision.

**Resolver Reasoning Display:** Implement a mechanism (e.g., a tooltip on the resolution indicator, an expandable section, a modal popup when clicking the indicator) to allow users to view the `resolver_reasoning` (and potentially `resolver_confidence_score`, `resolver_model_name`) from the corresponding `ScreeningResolution` record.

**Summary Metrics:** Display a summary for the current screening batch, such as 'X conflicts identified for resolution' and/or 'Y conflicts automatically resolved'.

### **4. Data Handling and State Management:**

**Ensure `screen_abstracts.py` correctly fetches and re-fetches `SearchResult` data** as needed to reflect updates made by the `ScreeningService` (e.g., populated `final_decision`, `resolution_id`).

**Manage Streamlit session state appropriately** to handle the multi-step process (initial screening, then resolution) and UI updates.

### **5. Error Handling:**

**Adapt error handling in `screen_abstracts.py`** to manage and display errors from the refactored `ScreeningService` calls, including the conflict resolution step.

## Acceptance Criteria (ACs)

- AC1: `screen_abstracts.py` correctly calls the refactored `ScreeningService.add_screening_decision` with appropriate `search_result_id`, `screening_strategy`, and `schemas.ScreeningResultCreate` data.
- AC2: `screen_abstracts.py` calls `ScreeningService.resolve_screening_conflicts_for_batch` after initial batch screening is complete.
- AC3: The UI correctly displays `SearchResult.final_decision` when available, otherwise shows original decisions and conflict status.
- AC4: A visual cue indicates decisions that have been automatically resolved by the resolver.
- AC5: Users can easily view the `resolver_reasoning` for resolved items.
- AC6: UI provides status updates during the conflict resolution phase.
- AC7: Summary metrics for conflict resolution in the batch are displayed.
- AC8: Session state and data refresh logic in `screen_abstracts.py` correctly handles the updated data post-resolution.
- AC9: Appropriate error handling is in place for all service interactions.
- AC10: Direct calls to `invoke_resolver_chain` are removed and replaced with proper service layer calls.
- AC11: Database persistence of resolver decisions is verified through UI testing.

## Technical Implementation Context

**Guidance:** Use the following details for implementation. Developer agent is expected to follow project standards in `docs/coding-standards.md` and understand the project structure in `docs/project-structure.md`.

- **Relevant Files:**
    - Files to Modify:
        - `src/sr_assistant/app/pages/screen_abstracts.py` (Primary focus)
        - Update imports to remove direct screening agent calls
    - Files to Reference:
        - `src/sr_assistant/app/services.py` (ScreeningService methods from Story 2.5)
        - `src/sr_assistant/core/models.py` (SearchResult.final_decision, resolution_id fields)
        - `src/sr_assistant/core/schemas.py` (ScreeningResultCreate, ResolverOutputSchema)

- **Key Technologies:**
    - Streamlit (for UI components and state management)
    - Python, Pydantic, SQLModel
    - Service layer patterns from `docs/coding-standards.md`

- **API Interactions / SDK Usage:**
    - Internal: `screen_abstracts.py` will call ScreeningService methods instead of direct agent functions
    - Remove direct imports and calls to: `invoke_resolver_chain`, resolver batch functions
    - Replace with: `ScreeningService.resolve_screening_conflicts_for_batch`

- **UI/UX Notes:**
    - Use `st.status()` or `st.spinner()` for conflict resolution progress indicators
    - Implement expandable sections or modals for resolver reasoning display
    - Color-code or icon-mark resolved decisions for visual distinction
    - Display summary metrics prominently after screening completion

- **Data Structures:**
    - Input: `schemas.ScreeningResultCreate` for service calls
    - Display: `SearchResult.final_decision` takes precedence over individual strategy decisions
    - Session state management for UI updates and data refresh

- **Environment Variables:**
    - None specific to this story (database connections handled by service layer)

- **Coding Standards Notes:**
    - Follow standards in `docs/coding-standards.md`
    - Remove direct session management related to screening/resolution data
    - Use service layer for all data persistence operations
    - Implement proper error handling with user-friendly error messages
    - Follow Streamlit best practices for state management and UI updates

- **Project Structure Alignment:**
    - UI logic remains in `src/sr_assistant/app/pages/screen_abstracts.py`
    - All business logic delegated to ScreeningService
    - Clear separation of concerns: UI ↔ Service ↔ Repository ↔ Database

## Testing Requirements

**Guidance:** Verify implementation against the ACs. Follow general testing approach in `docs/testing-strategy.md`.

- **Unit Tests:**
    - Test UI component behavior with mocked ScreeningService
    - Test that proper service methods are called with correct parameters
    - Test UI state management and data refresh logic
    - Test error handling scenarios
    - Mock all service calls to isolate UI logic

- **Integration Tests (AppTest-based):**
    - Test complete screening workflow through UI
    - Verify that ScreeningService is called correctly
    - Test UI displays final decisions and resolution indicators
    - Test resolver reasoning display functionality
    - Verify session state management across screening and resolution phases
    - Test error scenarios with service layer failures

## Tasks / Subtasks

- [ ] **Task 2.4.1: Refactor service call integration**
    - [ ] Remove direct imports of resolver chain functions
    - [ ] Replace `invoke_resolver_chain` calls with `ScreeningService.resolve_screening_conflicts_for_batch`
    - [ ] Update screening decision storage to use `ScreeningService.add_screening_decision`
    - [ ] Remove direct session management for screening operations

- [ ] **Task 2.4.2: Implement conflict resolution triggering**
    - [ ] Add call to `ScreeningService.resolve_screening_conflicts_for_batch` after batch screening
    - [ ] Pass correct parameters (review object, search_result_ids)
    - [ ] Handle service method errors appropriately

- [ ] **Task 2.4.3: Update UI to display final decisions**
    - [ ] Modify results display to prioritize `SearchResult.final_decision`
    - [ ] Show individual strategy decisions when final_decision is null
    - [ ] Implement conflict status indicators

- [ ] **Task 2.4.4: Add visual indicators for resolved decisions**
    - [ ] Add icons or tags for decisions resolved by AI
    - [ ] Implement visual distinction between resolved and unresolved conflicts
    - [ ] Ensure accessibility of visual cues

- [ ] **Task 2.4.5: Implement resolver reasoning display**
    - [ ] Add UI mechanism to view resolver reasoning (modal/expandable)
    - [ ] Fetch and display ScreeningResolution data
    - [ ] Include confidence score and model name if relevant

- [ ] **Task 2.4.6: Add status indicators for resolution process**
    - [ ] Implement progress indicator during conflict resolution
    - [ ] Show resolution status and completion messages
    - [ ] Handle and display resolution errors

- [ ] **Task 2.4.7: Implement summary metrics**
    - [ ] Display conflict count and resolution statistics
    - [ ] Update metrics after resolution completion
    - [ ] Include metrics in overall screening summary

- [ ] **Task 2.4.8: Update session state and data refresh logic**
    - [ ] Ensure SearchResult data is refreshed after resolution
    - [ ] Update session state management for multi-step process
    - [ ] Handle data consistency between screening and resolution phases

- [ ] **Task 2.4.9: Update error handling**
    - [ ] Implement error handling for all ScreeningService calls
    - [ ] Display user-friendly error messages
    - [ ] Handle partial failures in batch processing

- [ ] **Task 2.4.10: Write unit tests**
    - [ ] Unit tests for UI logic with mocked services
    - [ ] Test service method calls and parameter passing
    - [ ] Test UI state management and error scenarios

- [ ] **Task 2.4.11: Write AppTest integration tests**
    - [ ] End-to-end UI tests for complete screening workflow
    - [ ] Test UI displays and interactions with real service calls
    - [ ] Verify database persistence through UI testing

## Dependencies

- Story 2.1 (for ScreeningResolution model/repo and Pydantic schemas)
- Story 2.2 (for resolver_chain implementation)
- Story 2.5 (for refactored ScreeningService and new resolver methods) - **CRITICAL DEPENDENCY**

## Story Wrap Up (Agent Populates After Execution)

- **Agent Model Used:** `<Agent Model Name/Version>`
- **Completion Notes:** {Any notes about implementation choices, difficulties, or follow-up needed}
- **Change Log:**
    - Initial Creation by Product Owner Agent
