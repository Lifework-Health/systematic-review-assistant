# Story 4.13: Adherence to Logging Standards for Benchmark Module

**Status:** Draft

## Goal & Context

**User Story:** As a Developer, I want all new and modified Python code related to the benchmark module (including `tools/seed_benchmark_data.py` and code in `src/sr_assistant/benchmark/`) so that it adheres to logging standards outlined in `py/python-logging-rules.mdc` and general `docs/coding-standards.md` (e.g., use `logger.exception()` correctly).

**Context:** This story is a cross-cutting concern for all code developed within Epic 4. It ensures that the new benchmarking module follows established project logging practices for maintainability, debugging, and observability. This supports PRD FR7.1 ([`docs/prd-benchmark-may.md`](/docs/prd-benchmark-may.md)).

## Detailed Requirements

-   All Python code created or modified for stories US4.1 through US4.12 MUST adhere to the logging standards defined in:
    - `py/python-logging-rules.mdc`
    - The logging sections of `docs/coding-standards.md`.
-   Specifically, this includes:
    - Using `from loguru import logger` for all logging.
    - Correct usage of `logger.exception()` when handling exceptions (i.e., not manually adding the exception instance to the f-string as it's logged automatically).
    - Using `repr()` (e.g., `{variable!r}`) when logging variables in f-strings for clarity.
    - Using appropriate log levels (DEBUG, INFO, WARNING, ERROR, EXCEPTION) for different types of messages.
    - Ensuring log messages are clear, concise, and provide sufficient context.
    - Avoiding logging of sensitive information (e.g., full database connection strings with credentials, raw API keys, extensive PII unless specifically for auditable trace and properly secured).

## Acceptance Criteria (ACs)

- AC1: A code review of `tools/seed_benchmark_data.py` confirms adherence to project logging standards (Loguru usage, `logger.exception()`, `!r` for variables, appropriate levels).
- AC2: A code review of all new Python files in `src/sr_assistant/benchmark/` (e.g., `pages/human_benchmark_page.py`, `logic/metrics_calculator.py` if created) confirms adherence to project logging standards.
- AC3: Log outputs during manual testing of benchmark seeding (US4.1, US4.2) and benchmark run (US4.7, US4.8) demonstrate correct and informative logging.

## Technical Implementation Context

**Guidance:** This story is primarily about code review and adherence to existing standards. The developer agent should apply these standards throughout the implementation of other Epic 4 stories.

-   **Relevant Files:**
    - `tools/seed_benchmark_data.py`
    - All new `.py` files created under `src/sr_assistant/benchmark/`
    - Reference: `py/python-logging-rules.mdc`, `docs/coding-standards.md`.

-   **Key Technologies:**
    - Loguru
    - Python 3.12

-   **API Interactions / SDK Usage:**
    - Not applicable, focuses on how logging is done around other interactions.

-   **UI/UX Notes:**
    - Not applicable.

-   **Data Structures:**
    - Not applicable.

-   **Environment Variables:**
    - Not directly applicable, though log levels might be configurable via env vars as per `docs/environment-vars.md` (`LOG_LEVEL`).

-   **Coding Standards Notes:**
    - The core of this story is to ensure all previously defined coding and logging standards are met for the new module.

## Testing Requirements

**Guidance:** Verify implementation against the ACs.

-   **Unit Tests:**
    - Unit tests for other stories should implicitly verify that logging calls do not cause errors. Specific tests for log output formatting are generally not needed unless complex logging utility functions are built.
-   **Integration Tests:**
    - N/A for logging standards directly, but logs generated during integration tests can be inspected.
-   **Manual/CLI Verification:**
    - Review code for adherence to logging rules.
    - Run the seeding script and the benchmark UI, then inspect console output and log files (`app.log`, `logs/seed_benchmark_data.log`) to ensure logs are informative, correctly formatted (e.g., `!r` for variables), and that exceptions are logged properly with `logger.exception()`.

## Tasks / Subtasks

- [ ] Task 1: Review `tools/seed_benchmark_data.py` against `py/python-logging-rules.mdc` and `docs/coding-standards.md`. Apply any necessary corrections.
- [ ] Task 2: As new Python files are created in `src/sr_assistant/benchmark/` for other Epic 4 stories, ensure all logging within them adheres to project standards from the outset.
- [ ] Task 3: During manual testing of other Epic 4 stories (e.g., US4.7, US4.8), inspect logs to confirm quality and correctness.

## Story Wrap Up (Agent Populates After Execution)

-   **Agent Model Used:** `<Agent Model Name/Version>`
-   **Completion Notes:** {Any notes about implementation choices, difficulties, or follow-up needed}
-   **Change Log:** {Track changes _within this specific story file_ if iterations occur}
    - Initial Draft
    - ...
