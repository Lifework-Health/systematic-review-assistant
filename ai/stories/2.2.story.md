# Story 2.2: Define and Implement Resolver Agent (Chain)

**Status:** Draft

## Goal & Context

**User Story:** As a developer, I need a robust LLM agent (chain) that can take disagreement context as input and produce a final, reasoned screening decision, so that conflicts can be resolved automatically.

**Context:** This story is part of Epic 2 ("Resolver Agent Implementation and Integration"). It focuses on creating the core AI logic for conflict resolution. This involves defining the Pydantic schema for the resolver's output (`ScreeningResolutionSchema`), crafting the LLM prompt, and constructing the LangChain Expression Language (LCEL) chain. This chain will be invoked by the `ScreeningService` (Story 2.5) when disagreements are identified between the conservative and comprehensive screening reviewers. The successful completion of Story 2.1, which defines `ScreeningResolutionSchema` and sets up data persistence for resolutions, is a prerequisite.

## Detailed Requirements

(Copied from `docs/epic2-recovery-resolver-implementation.md#Story-2.2`)

- Review and update the `ScreeningResolutionSchema` Pydantic schema in `src/sr_assistant/core/schemas.py`. Specifically address the `resolver_include` field: evaluate its necessity and utility in light of a definitive `final_decision` field being the primary outcome (as suggested in FR5 of `docs/prd-resolver.md`). If the `resolver_include` field (or a repurposed version) is retained, ensure its name is appropriate (e.g., `contributing_strategies` or similar if it serves a new purpose) and its type is `list[ScreeningStrategyType]` (from `src/sr_assistant/core/types.py`) instead of `list[str]`. The schema must accurately reflect the data intended for populating/deriving the `ScreeningResolution` model.
- Update/Create the `resolver_prompt` (system and human messages) in `screening_agents.py` to clearly instruct the LLM. The prompt should take all necessary context: `SearchResult` data, `SystematicReview` protocol (PICO, exclusion criteria), and the conservative/comprehensive `ScreenAbstractResult` details. The prompt must align with the (potentially updated) `ScreeningResolutionSchema` for its output structure, especially emphasizing the `final_decision`.
- Construct the `resolver_chain` using the `RESOLVER_MODEL` (as defined in `src/sr_assistant/app/config.py` or environment variables, expected to be Google AI's Gemini model), the refined prompt, and structured output parsing (to `ScreeningResolutionSchema`).
- Implement error handling and retries for the `resolver_chain` similar to existing screening chains.

## Acceptance Criteria (ACs)

(Copied from `docs/epic2-recovery-resolver-implementation.md#Story-2.2`)

- AC1: `ScreeningResolutionSchema` in `schemas.py` is correctly defined/updated; if a field like `resolver_include` is kept, it has an appropriate name and type (`list[ScreeningStrategyType]`).
- AC2: `resolver_prompt` is implemented and includes placeholders for all required context and aligns with the output schema.
- AC3: `resolver_chain` is defined, uses the specified model, prompt, and structured output parsing to `ScreeningResolutionSchema`.
- AC4: The chain correctly processes realistically structured input data (which may contain specific test values for known scenarios) and produces an output that successfully parses into a `ScreeningResolutionSchema` instance.
- AC5: Integration test for `resolver_chain` (running against the actual LLM API, using approved quotas) confirms it can be invoked with representative real context and returns an output that parses correctly to the `ScreeningResolutionSchema`.

## Technical Implementation Context

**Guidance:** Use the following details for implementation. Developer agent is expected to follow project standards in `docs/coding-standards.md`, `docs/naming-conventions.md`, and understand the project structure in `docs/project-structure.md`. Refer to `docs/api-reference.md` for service interactions and `docs/data-models.md` for schema details.

- **Relevant Files:**
  - Files to Modify:
    - `src/sr_assistant/core/schemas.py` (for `ScreeningResolutionSchema` adjustments)
    - `src/sr_assistant/app/agents/screening_agents.py` (for `resolver_prompt` and `resolver_chain` implementation)
  - Files to Create (if not already stubs by Architect):
    - Potentially a new test file in `tests/integration/app/agents/` for `resolver_chain` integration tests, or add to existing.
    - Potentially a new test file in `tests/unit/app/agents/` for `resolver_prompt` or helper function unit tests.

- **Key Technologies:**
  - Python, LangChain (LCEL for chain construction, structured output parsing)
  - Pydantic (for `ScreeningResolutionSchema`)
  - Google AI API (Gemini models, via `langchain-google-genai`)

- **API Interactions / SDK Usage:**
  - `langchain_google_genai.ChatGoogleGenerativeAI` for interacting with the `RESOLVER_MODEL`.
  - LangChain's `PromptTemplate` or `ChatPromptTemplate`, and `StructuredOutputParser` (or Pydantic output parser).

- **Data Structures:**
  - `schemas.ScreeningResolutionSchema` (from `src/sr_assistant/core/schemas.py` - defined in Story 2.1, to be reviewed/updated here). This schema defines the direct output of the resolver LLM.
    - Key LLM-populated fields: `resolver_decision: ScreeningDecisionType`, `resolver_reasoning: str`, `resolver_confidence_score: float`.
    - The `resolver_include: list[ScreeningStrategyType]` field is under review in this story.
    - Other fields like `review_id`, `search_result_id` are populated by the `ScreeningService` when storing the resolution, not by the LLM chain itself.
  - Input to the resolver chain: A dictionary containing all necessary context, as per `ScreeningService.prepare_resolver_inputs` (defined in `docs/api-reference.md`). This typically includes:
    - `search_result_title: str`
    - `search_result_abstract: str`
    - `search_result_year: str | None`
    - `search_result_journal: str | None`
    - `search_result_authors: list[str] | None`
    - `review_research_question: str`
    - `review_inclusion_criteria: str` (Noting this uses the stringified version, as per current architecture)
    - `review_exclusion_criteria: str`
    - `conservative_decision: ScreeningDecisionType`
    - `conservative_rationale: str`
    - `conservative_confidence: float`
    - `comprehensive_decision: ScreeningDecisionType`
    - `comprehensive_rationale: str`
    - `comprehensive_confidence: float`

- **Environment Variables:**
  - `GOOGLE_API_KEY` (or mechanism used by `langchain-google-genai` for authentication).
  - `RESOLVER_MODEL_NAME` (e.g., "gemini-1.5-pro-preview-0514", sourced from `src/sr_assistant/app/config.py`).

- **Coding Standards Notes:**
  - Follow standards in `docs/coding-standards.md`.
  - Prompts should be clear, concise, and provide sufficient context for the LLM.
  - Ensure robust parsing of the LLM output into `ScreeningResolutionSchema`.
  - Implement retry mechanisms for LLM calls (e.g., using LangChain's built-in retry capabilities with `with_retry`).

- **Project Structure Alignment:**
  - Resolver chain and prompt logic should reside in `src/sr_assistant/app/agents/screening_agents.py`.
  - `ScreeningResolutionSchema` updates in `src/sr_assistant/core/schemas.py`.

## Testing Requirements

**Guidance:** Verify implementation against the ACs. Follow general testing approach in `docs/testing-strategy.md`.

- **Unit Tests:**
  - Test any helper functions used for prompt templating.
  - Test the construction of the `resolver_prompt` with various inputs to ensure it formats correctly.
  - Test the output parser for `ScreeningResolutionSchema` with sample valid and invalid LLM-like outputs.
- **Integration Tests:** (AC5)
  - Create integration tests for the `resolver_chain` that call the actual LLM API (`RESOLVER_MODEL`).
  - These tests should use representative input data (simulating disagreements) and verify that the output:
    - Successfully parses into a `ScreeningResolutionSchema` instance.
    - Produces a plausible `resolver_decision` and `resolver_reasoning` given the inputs.
  - Cover different types of disagreements if feasible (e.g., INCLUDE vs. EXCLUDE).
  - Ensure these tests are marked appropriately (e.g., with a pytest marker like `@pytest.mark.integration` and `@pytest.mark.llm_integration`) and manage API costs/quotas (e.g., run sparingly, use smaller contexts if possible for testing chain mechanics).
  - Refer to `docs/epic3-recovery-testing-and-integrity.md#Story-3.2` for more details on resolver integration test scenarios.

## Tasks / Subtasks

(Derived from `docs/epic2-recovery-resolver-implementation.md#Story-2.2` and expanded)

- [ ] Task 2.2.1: Review `ScreeningResolutionSchema` in `src/sr_assistant/core/schemas.py`.
    - [ ] Evaluate the `resolver_include` field's utility and name.
    - [ ] If retained/renamed, ensure its type is `list[ScreeningStrategyType]`.
    - [ ] Ensure other LLM-populated fields (`resolver_decision`, `resolver_reasoning`, `resolver_confidence_score`) are correctly defined. Fields populated by the service layer (like `review_id`, `search_result_id`) should NOT be part of the direct LLM output contract if a stricter LLM output schema is preferred. For now, align with existing `ScreeningResolutionSchema` and document which fields are LLM-provided vs. service-provided.
- [ ] Task 2.2.2: Design and implement the `resolver_prompt` (system and human messages) in `src/sr_assistant/app/agents/screening_agents.py`.
    - [ ] Define clear instructions for the LLM, including its role, the context it will receive, and the desired output format (`ScreeningResolutionSchema`).
    - [ ] Incorporate placeholders for all necessary input variables (title, abstract, original decisions, rationales, review protocol, etc.).
    - [ ] Emphasize the importance of the `resolver_decision` and `resolver_reasoning`.
- [ ] Task 2.2.3: Construct the `resolver_chain` in `src/sr_assistant/app/agents/screening_agents.py`.
    - [ ] Instantiate `ChatGoogleGenerativeAI` with the `RESOLVER_MODEL_NAME`.
    - [ ] Combine the prompt template with the LLM.
    - [ ] Implement structured output parsing to `ScreeningResolutionSchema` (e.g., using PydanticOutputFunctionsParser or JsonOutputParser with Pydantic validation).
    - [ ] Add error handling (e.g., `try-except` blocks around chain invocation if handled outside LangChain's retries).
    - [ ] Implement retry logic (e.g., `.with_retry()`).
- [ ] Task 2.2.4: Write unit tests for prompt generation and output parsing.
- [ ] Task 2.2.5: Write integration tests for the `resolver_chain` (AC5).
    - [ ] Prepare mock input data representing realistic disagreement scenarios.
    - [ ] Invoke the chain against the actual LLM API.
    - [ ] Validate that the output is a parsable `ScreeningResolutionSchema` instance and that the content is coherent.

## Story Wrap Up (Agent Populates After Execution)

- **Agent Model Used:** `<Agent Model Name/Version>`
- **Completion Notes:** {Any notes about implementation choices, difficulties, or follow-up needed}
- **Change Log:**
  - Initial Draft by Technical Scrum Master Agent 