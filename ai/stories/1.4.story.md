# Story 1.4: End-to-End PubMed Search Workflow Stabilization

**Status:** Draft

## Goal & Context

**User Story:** As a user, I want to perform a PubMed search using the `search.py` interface and have the results correctly fetched, stored, and displayed without errors, so that I can reliably gather articles for my systematic review.

**Context:** This story is part of Epic 1 ("Search and Service Layer Stabilization"). It aims to ensure the entire PubMed search workflow is functional and stable, building upon the refactored `search.py` (Story 1.1), `SearchService` (Story 1.2), and `SearchResultRepository` (Story 1.3). Successful completion of this story means the core PubMed search functionality is reliable from UI to database.

## Detailed Requirements

(Copied from `docs/epic1-recovery-search-stabilization.md#Story-1.4`)

- The entire flow from entering a search query in `search.py`, triggering `SearchService`, fetching from PubMed, transforming to `SearchResult` objects, storing via `SearchResultRepository`, and displaying in `search.py` must be functional.
- All linter errors in `search.py`, `services.py` (related to search), and `repositories.py` (related to `SearchResultRepository`) that impact this workflow must be resolved.
- The system should prevent duplicate storage of the same PubMed article for the same review.

## Acceptance Criteria (ACs)

(Copied from `docs/epic1-recovery-search-stabilization.md#Story-1.4`)

- AC1: User can successfully execute a PubMed search from the `search.py` UI.
- AC2: Search results are displayed correctly in the UI using `SearchResult` data (specifically `schemas.SearchResultRead`).
- AC3: `SearchResult` instances are correctly persisted in the database via the service and repository layers.
- AC4: No Python errors or exceptions occur during the PubMed search and result display workflow.
- AC5: Attempting to store the same PubMed article for the same review multiple times does not create duplicate entries (verified via `exists_by_source_id` or similar logic in service).

## Technical Implementation Context

**Guidance:** Use the following details for implementation. Developer agent is expected to follow project standards in `docs/coding-standards.md` and understand the project structure in `docs/project-structure.md`. Only story-specific details are included below.

- **Relevant Files:**
  - Files to Modify/Verify:
    - `src/sr_assistant/app/pages/search.py`
    - `src/sr_assistant/app/services.py` (specifically `SearchService`)
    - `src/sr_assistant/core/repositories.py` (specifically `SearchResultRepository`)
    - `src/sr_assistant/core/models.py` (ensure `SearchResult` model is stable)
    - `src/sr_assistant/core/schemas.py` (ensure `SearchResultRead` is stable)

- **Key Technologies:**
  - Streamlit (for UI)
  - Python, Pydantic, SQLModel, SQLAlchemy
  - BioPython (or equivalent for PubMed API interaction, encapsulated in `SearchService`)

- **API Interactions / SDK Usage:**
  - Primarily internal:
    - `search.py` calls `SearchService.search_pubmed_and_store_results`.
    - `SearchService` calls `SearchResultRepository` methods (e.g., `add_all`, `exists_by_source_id`).
    - `SearchService` interacts with PubMed API.

- **UI/UX Notes:**
  - Focus is on workflow stability. UI should be functional as refactored in Story 1.1.

- **Data Structures:**
  - `schemas.SearchResultRead` (for UI display and service return type)
  - `models.SearchResult` (for database persistence)

- **Environment Variables:**
  - `NCBI_API_KEY` and `NCBI_EMAIL` (used by `SearchService`). Ensure these are set in `.env` or `.env.local` for local testing.

- **Coding Standards Notes:**
  - Follow standards in `docs/coding-standards.md`.
  - Ensure duplicate prevention logic in `SearchService` (likely within `search_pubmed_and_store_results` or a helper) is robust. This typically involves checking if a result with the same `source_id` (e.g., PMID) and `review_id` already exists before adding. The `exists_by_source_id` method in `SearchResultRepository` (if implemented as per Story 1.3 definition in the epic) should be utilized.

- **Project Structure Alignment:**
  - Verification and potential minor fixes may span across `pages`, `services`, and `core` directories as listed in "Relevant Files".

## Testing Requirements

**Guidance:** Verify implementation against the ACs using the following tests. Follow general testing approach in `docs/testing-strategy.md`.

- **Unit Tests:**
  - Existing unit tests for `search.py`, `SearchService`, and `SearchResultRepository` (from Stories 1.1, 1.2, 1.3) should cover most component-level logic.
  - If specific logic for duplicate prevention in `SearchService` is complex, ensure it has dedicated unit tests (mocking repository calls).
- **Integration Tests:**
  - An integration test for `SearchService.search_pubmed_and_store_results` should exist (from Story 1.2) that:
    - Mocks the PubMed API call to return a fixed set of known articles.
    - Verifies that articles are correctly mapped, stored in the test database, and duplicates are handled (i.e., not re-stored if called again with same data for the same review).
    - Verifies that `schemas.SearchResultRead` objects are returned.
- **Manual/CLI Verification:**
  - Thorough manual testing of the PubMed search workflow via the Streamlit UI is critical for this story.
    - Select an existing review or create a new one.
    - Perform a PubMed search with a query known to return a few results.
    - Verify results are displayed correctly.
    - Verify data is persisted in the database (using a DB tool or a `mcp_postgres-sra_query` if available to the agent).
    - Perform the same search again for the same review and verify no duplicate entries are created in the database, and the UI still shows the results correctly (count should not increase).
    - Check application logs for any errors.

## Tasks / Subtasks

(Derived from `docs/epic1-recovery-search-stabilization.md#Story-1.4` and expanded)

- [ ] Task 1.4.1: Perform manual end-to-end testing of the PubMed search workflow:
    - Start the Streamlit application.
    - Navigate to an existing systematic review or create a new one.
    - Use the search page (`search.py`) to perform a PubMed search with a simple query expected to yield results.
    - Observe UI for correct display of results (count, titles, abstracts).
    - Check for any Python errors in the terminal or `st.error` messages in the UI.
- [ ] Task 1.4.2: Verify data persistence:
    - After a successful search, use a database inspection tool (or `mcp_postgres-sra_query`) to confirm that `SearchResult` records corresponding to the displayed articles are correctly saved in the `search_results` table, linked to the correct `review_id`.
    - Confirm fields like `source_db`, `source_id`, `title`, `abstract`, `year`, `raw_data` are populated.
- [ ] Task 1.4.3: Verify duplicate prevention:
    - Re-run the same PubMed search query for the same systematic review.
    - Verify that the number of displayed results does not change (unless new, unique articles were published matching the query).
    - Verify in the database that no duplicate `SearchResult` records (same `source_id` for the same `review_id`) were created. The `SearchService` should handle this, possibly using `SearchResultRepository.exists_by_source_id`.
- [ ] Task 1.4.4: Review and resolve any critical linter errors or runtime exceptions encountered in `search.py`, `services.py` (specifically `SearchService`'s PubMed path), and `repositories.py` (`SearchResultRepository`) that impede the workflow.
- [ ] Task 1.4.5: (If not already covered by Story 1.2/1.3 tests) Review or add integration tests for `SearchService` that specifically verify the duplicate prevention logic.

## Story Wrap Up (Agent Populates After Execution)

- **Agent Model Used:** `<Agent Model Name/Version>`
- **Completion Notes:** {Any notes about implementation choices, difficulties, or follow-up needed}
- **Change Log:**
  - Initial Draft 